{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>João Miguel, Bianca Comparato, Michel Gomes, R...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>August 14, 2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>4 Seasons</td>\n",
       "      <td>International TV Shows, TV Dramas, TV Sci-Fi &amp;...</td>\n",
       "      <td>In a future where the elite inhabit an island ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>Movie</td>\n",
       "      <td>7:19</td>\n",
       "      <td>Jorge Michel Grau</td>\n",
       "      <td>Demián Bichir, Héctor Bonilla, Oscar Serrano, ...</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>December 23, 2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>93 min</td>\n",
       "      <td>Dramas, International Movies</td>\n",
       "      <td>After a devastating earthquake hits Mexico Cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3</td>\n",
       "      <td>Movie</td>\n",
       "      <td>23:59</td>\n",
       "      <td>Gilbert Chan</td>\n",
       "      <td>Tedd Chan, Stella Chung, Henley Hii, Lawrence ...</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>December 20, 2018</td>\n",
       "      <td>2011</td>\n",
       "      <td>R</td>\n",
       "      <td>78 min</td>\n",
       "      <td>Horror Movies, International Movies</td>\n",
       "      <td>When an army recruit is found dead, his fellow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s4</td>\n",
       "      <td>Movie</td>\n",
       "      <td>9</td>\n",
       "      <td>Shane Acker</td>\n",
       "      <td>Elijah Wood, John C. Reilly, Jennifer Connelly...</td>\n",
       "      <td>United States</td>\n",
       "      <td>November 16, 2017</td>\n",
       "      <td>2009</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>80 min</td>\n",
       "      <td>Action &amp; Adventure, Independent Movies, Sci-Fi...</td>\n",
       "      <td>In a postapocalyptic world, rag-doll robots hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s5</td>\n",
       "      <td>Movie</td>\n",
       "      <td>21</td>\n",
       "      <td>Robert Luketic</td>\n",
       "      <td>Jim Sturgess, Kevin Spacey, Kate Bosworth, Aar...</td>\n",
       "      <td>United States</td>\n",
       "      <td>January 1, 2020</td>\n",
       "      <td>2008</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>123 min</td>\n",
       "      <td>Dramas</td>\n",
       "      <td>A brilliant group of students become card-coun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  show_id     type  title           director  \\\n",
       "0      s1  TV Show     3%                NaN   \n",
       "1      s2    Movie   7:19  Jorge Michel Grau   \n",
       "2      s3    Movie  23:59       Gilbert Chan   \n",
       "3      s4    Movie      9        Shane Acker   \n",
       "4      s5    Movie     21     Robert Luketic   \n",
       "\n",
       "                                                cast        country  \\\n",
       "0  João Miguel, Bianca Comparato, Michel Gomes, R...         Brazil   \n",
       "1  Demián Bichir, Héctor Bonilla, Oscar Serrano, ...         Mexico   \n",
       "2  Tedd Chan, Stella Chung, Henley Hii, Lawrence ...      Singapore   \n",
       "3  Elijah Wood, John C. Reilly, Jennifer Connelly...  United States   \n",
       "4  Jim Sturgess, Kevin Spacey, Kate Bosworth, Aar...  United States   \n",
       "\n",
       "          date_added  release_year rating   duration  \\\n",
       "0    August 14, 2020          2020  TV-MA  4 Seasons   \n",
       "1  December 23, 2016          2016  TV-MA     93 min   \n",
       "2  December 20, 2018          2011      R     78 min   \n",
       "3  November 16, 2017          2009  PG-13     80 min   \n",
       "4    January 1, 2020          2008  PG-13    123 min   \n",
       "\n",
       "                                           listed_in  \\\n",
       "0  International TV Shows, TV Dramas, TV Sci-Fi &...   \n",
       "1                       Dramas, International Movies   \n",
       "2                Horror Movies, International Movies   \n",
       "3  Action & Adventure, Independent Movies, Sci-Fi...   \n",
       "4                                             Dramas   \n",
       "\n",
       "                                         description  \n",
       "0  In a future where the elite inhabit an island ...  \n",
       "1  After a devastating earthquake hits Mexico Cit...  \n",
       "2  When an army recruit is found dead, his fellow...  \n",
       "3  In a postapocalyptic world, rag-doll robots hi...  \n",
       "4  A brilliant group of students become card-coun...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/netflix_titles.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['description'] = data['description'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование признаков TF-IDF\n",
    "model = TfidfVectorizer(stop_words='english')\n",
    "feature_matrix = model.fit_transform(data['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7787, 17905)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение косинусной близости\n",
    "# Мы используем здесь linear_kernel(), а не cosine_similarity(), так как в косинусном расстоянии в знаменателе реализуется нормировка векторов, \n",
    "# а TF-IDF создаёт уже нормализованные векторы.\n",
    "cosine_sim = linear_kernel(feature_matrix, feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Массив фильмов с их индексами\n",
    "indices = pd.Series(data.index,index=data['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    #вычисляем попарные коэффициенты косинусной близости\n",
    "    scores = list(enumerate(cosine_sim[idx]))\n",
    "    #сортируем фильмы на основании коэффициентов косинусной близости по убыванию\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    #выбираем десять наибольших значений косинусной близости; нулевую не берём, т. к. это тот же фильм\n",
    "    scores = scores[1:11]\n",
    "    #забираем индексы\n",
    "    ind_movie = [i[0] for i in scores]\n",
    "    #возвращаем названия по индексам\n",
    "    return data['title'].iloc[ind_movie]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709                Balto 2: Wolf Quest\n",
       "7446                           Vroomiz\n",
       "1338    Chilling Adventures of Sabrina\n",
       "7388                          Vampires\n",
       "1770                          Dinotrux\n",
       "2767                     Hold the Dark\n",
       "5540                 Shanghai Fortress\n",
       "4041                             Mercy\n",
       "2582                       Half & Half\n",
       "1365        Christmas in the Heartland\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('Balto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "КОЛЛАБОРАТИВНАЯ ФИЛЬТРАЦИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD, KNNBasic, accuracy\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0271678039029761"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': False\n",
    "}\n",
    "\n",
    "# memory-basic-подход\n",
    "knn = KNNBasic(sim_options=sim_options)\n",
    "knn.fit(trainset)\n",
    "predictions = knn.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(predictions)\n",
    "pred.sort_values(by=['est'],inplace=True,ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['234', '427', '568', '174']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recom = pred[pred.uid =='849']['iid'].to_list()\n",
    "recom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0174852296380237"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user-based-подход\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': True\n",
    "}\n",
    "\n",
    "knn = KNNBasic(sim_options=sim_options)\n",
    "knn.fit(trainset)\n",
    "predictions = knn.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9417423610952942"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model-based-подход\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "predictions = model.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ГИБРИДНЫЕ МОДЕЛИ РЕКОМЕНДАТЕЛЬНЫХ СИСТЕМ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightfm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\SkillFactory\\SF_DataScience\\Current_tasks\\MATH_15.ipynb Ячейка 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/SkillFactory/SF_DataScience/Current_tasks/MATH_15.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlightfm\u001b[39;00m \u001b[39mimport\u001b[39;00m LightFM\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/SkillFactory/SF_DataScience/Current_tasks/MATH_15.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlightfm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcross_validation\u001b[39;00m \u001b[39mimport\u001b[39;00m random_train_test_split\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/SkillFactory/SF_DataScience/Current_tasks/MATH_15.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlightfm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevaluation\u001b[39;00m \u001b[39mimport\u001b[39;00m precision_at_k, recall_at_k\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightfm'"
     ]
    }
   ],
   "source": [
    "#from lightfm import LightFM\n",
    "#from lightfm.cross_validation import random_train_test_split\n",
    "#from lightfm.evaluation import precision_at_k, recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('data/math15/ratings.csv') #поставленные оценки\n",
    "books = pd.read_csv('data/math15/books.csv') #информация о книгах\n",
    "tags = pd.read_csv('data/math15/tags.csv') #информация о тегах\n",
    "book_tags = pd.read_csv('data/math15/book_tags.csv') #книги с тегами "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix = csr_matrix((ratings.rating,(ratings.user_id,ratings.book_id))) \n",
    "# передаём в качестве аргументов в функцию выставленный рейтинг (это будут значения матрицы), \n",
    "# а также id пользователя и id книги (это будут индексы для строк и столбцов матрицы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь нам необходимо составить матрицу с метаданными. В качестве индексов будут выступать id книги и id тега, \n",
    "# и если у этой книги есть рассматриваемый тег, то на пересечении соответствующих строки и столбца будет выставлена единица.\n",
    "meta_matrix  = csr_matrix(([1]*len(book_tags),(book_tags.goodreads_book_id,book_tags.tag_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = LightFM(loss='warp', #определяем функцию потерь\n",
    "                #random_state=13, #фиксируем случайное разбиение\n",
    "                #no_components=100) #размерность вектора для представления данных в модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве функции потерь мы выбрали значение 'warp', хотя, разумеется, это не единственный вариант. В модуле LightFM представлены следующие функции потерь:\n",
    "\n",
    "'logistic' — логистическая функция. Полезна в случаях, когда есть как положительные, так и отрицательные взаимодействия, например 1 и -1.\n",
    "\n",
    "'bpr' — байесовский персонализированный рейтинг. Можно применять, когда присутствуют только положительные взаимодействия.\n",
    "\n",
    "'warp' — парный взвешенный приблизительный ранг. Используется, если необходимо повысить качество именно в верхней части списка рекомендаций.\n",
    "\n",
    "'warp-kos' — модификация warp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\SkillFactory\\SF_DataScience\\Current_tasks\\MATH_15.ipynb Ячейка 26\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/SkillFactory/SF_DataScience/Current_tasks/MATH_15.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train,test \u001b[39m=\u001b[39m random_train_test_split(ratings_matrix, test_percentage\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m13\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random_train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "#train,test = random_train_test_split(ratings_matrix, test_percentage=0.3, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model.fit(train, item_features = meta_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prec_score = precision_at_k(\n",
    "                     #model,\n",
    "                     #test,\n",
    "                     #item_features = meta_matrix).mean() \n",
    "#print(prec_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEEP LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/math15/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_books = df.book_id.nunique()\n",
    "n_users = df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём эмбеддинги для книг\n",
    "book_input = Input(shape=[1], name=\"Book-Input\")\n",
    "book_embedding = Embedding(n_books+1, 5, name=\"Book-Embedding\")(book_input)\n",
    "book_vec = Flatten(name=\"Flatten-Books\")(book_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаём эмбеддинги для пользователей\n",
    "user_input = Input(shape=[1], name=\"User-Input\")\n",
    "user_embedding = Embedding(n_users+1, 5, name=\"User-Embedding\")(user_input)\n",
    "user_vec = Flatten(name=\"Flatten-Users\")(user_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соединяем ембеддинги\n",
    "conc = Concatenate()([book_vec, user_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Далее начинаем «собирать» нашу нейронную сеть из слоёв. Dense обозначает полносвязный слой. \n",
    "# Также мы обозначаем для него количество нейронов и данные, которые идут на вход.\n",
    "fc1 = Dense(128, activation='relu')(conc)\n",
    "fc2 = Dense(32, activation='relu')(fc1)\n",
    "out = Dense(1)(fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем модель — передаём входные данные для книг и пользователей, а также архитектуру нейронной сети:\n",
    "model2 = Model([user_input, book_input], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Также нам необходимо задать алгоритм оптимизации и метрику, которую мы будем оптимизировать. \n",
    "# В данном случае будем использовать метод adam и среднеквадратичную ошибку\n",
    "model2.compile(optimizer = 'adam',loss =  'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "24544/24544 [==============================] - 243s 10ms/step - loss: 0.8007\n",
      "Epoch 2/5\n",
      "24544/24544 [==============================] - 182s 7ms/step - loss: 0.6893\n",
      "Epoch 3/5\n",
      "24544/24544 [==============================] - 175s 7ms/step - loss: 0.6618\n",
      "Epoch 4/5\n",
      "24544/24544 [==============================] - 182s 7ms/step - loss: 0.6373\n",
      "Epoch 5/5\n",
      "24544/24544 [==============================] - 185s 8ms/step - loss: 0.6181\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "# В параметр эпох передаём значение 5: у нас будет реализовано пять эпох — пять обучений нейронной сети. \n",
    "# На каждой из эпох обновляются веса для минимизации ошибки.\n",
    "history = model2.fit([train.user_id, train.book_id], train.rating, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6136/6136 [==============================] - 9s 1ms/step - loss: 0.7096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7096015810966492"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate([test.user_id, test.book_id], test.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24544/24544 [==============================] - 166s 7ms/step - loss: 0.6385\n",
      "Epoch 2/10\n",
      "24544/24544 [==============================] - 176s 7ms/step - loss: 0.5910\n",
      "Epoch 3/10\n",
      "24544/24544 [==============================] - 191s 8ms/step - loss: 0.5717\n",
      "Epoch 4/10\n",
      "24544/24544 [==============================] - 169s 7ms/step - loss: 0.5536\n",
      "Epoch 5/10\n",
      "24544/24544 [==============================] - 173s 7ms/step - loss: 0.5375\n",
      "Epoch 6/10\n",
      "24544/24544 [==============================] - 144s 6ms/step - loss: 0.5241\n",
      "Epoch 7/10\n",
      "24544/24544 [==============================] - 158s 6ms/step - loss: 0.5131\n",
      "Epoch 8/10\n",
      "24544/24544 [==============================] - 152s 6ms/step - loss: 0.5036\n",
      "Epoch 9/10\n",
      "24544/24544 [==============================] - 137s 6ms/step - loss: 0.4952\n",
      "Epoch 10/10\n",
      "24544/24544 [==============================] - 156s 6ms/step - loss: 0.4880\n",
      "6136/6136 [==============================] - 7s 1ms/step - loss: 0.7819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.781889021396637"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обычно для улучшения качества модели каким-то образом модифицируют нейронную сеть: дополняют её, увеличивают время обучения. \n",
    "# Добавим ещё один полносвязный слой с восемью нейронами после полносвязного слоя с 32 нейронами. \n",
    "# Обучим нейронную сеть, реализовав десять эпох:\n",
    "fc1 = Dense(128, activation='relu')(conc)\n",
    "fc2 = Dense(32, activation='relu')(fc1)\n",
    "fc3 = Dense(8, activation='relu')(fc2)\n",
    "out = Dense(1)(fc3)\n",
    "\n",
    "model2 = Model([user_input, book_input], out)\n",
    "model2.compile('adam', 'mean_squared_error')\n",
    "result = model2.fit([train.user_id, train.book_id], train.rating, epochs=10, verbose=1)\n",
    "model2.evaluate([test.user_id, test.book_id], test.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c97e36f5c1aa02871b4149eafcab2ec871d39d20911a3254ab29c2172503796d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
