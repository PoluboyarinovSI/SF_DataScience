{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJnHQn4htNIF",
        "outputId": "a9944aca-2fa0-4a26-f0ce-1b32ccd9705a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (11.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (1.4.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.28.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: xxhash in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2023.5.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.15.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: colorama in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Collecting tokenizers==0.10.0rc1\n",
            "  Using cached tokenizers-0.10.0rc1.tar.gz (208 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Building wheels for collected packages: tokenizers\n",
            "  Building wheel for tokenizers (pyproject.toml): started\n",
            "  Building wheel for tokenizers (pyproject.toml): finished with status 'error'\n",
            "Failed to build tokenizers\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Building wheel for tokenizers (pyproject.toml) did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [51 lines of output]\n",
            "      running bdist_wheel\n",
            "      running build\n",
            "      running build_py\n",
            "      creating build\n",
            "      creating build\\lib.win-amd64-cpython-310\n",
            "      creating build\\lib.win-amd64-cpython-310\\tokenizers\n",
            "      copying py_src\\tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\n",
            "      creating build\\lib.win-amd64-cpython-310\\tokenizers\\models\n",
            "      copying py_src\\tokenizers\\models\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\models\n",
            "      creating build\\lib.win-amd64-cpython-310\\tokenizers\\decoders\n",
            "      copying py_src\\tokenizers\\decoders\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\decoders\n",
            "      creating build\\lib.win-amd64-cpython-310\\tokenizers\\normalizers\n",
            "      copying py_src\\tokenizers\\normalizers\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\normalizers\n",
            "      creating build\\lib.win-amd64-cpython-310\\tokenizers\\pre_tokenizers\n",
            "      copying py_src\\tokenizers\\pre_tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\pre_tokenizers\n",
            "      creating build\\lib.win-amd64-cpython-310\\tokenizers\\processors\n",
            "      copying py_src\\tokenizers\\processors\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\processors\n",
            "      creating build\\lib.win-amd64-cpython-310\\tokenizers\\trainers\n",
            "      copying py_src\\tokenizers\\trainers\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\trainers\n",
            "      creating build\\lib.win-amd64-cpython-310\\tokenizers\\implementations\n",
            "      copying py_src\\tokenizers\\implementations\\base_tokenizer.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\implementations\n",
            "      copying py_src\\tokenizers\\implementations\\bert_wordpiece.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\implementations\n",
            "      copying py_src\\tokenizers\\implementations\\byte_level_bpe.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\implementations\n",
            "      copying py_src\\tokenizers\\implementations\\char_level_bpe.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\implementations\n",
            "      copying py_src\\tokenizers\\implementations\\sentencepiece_bpe.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\implementations\n",
            "      copying py_src\\tokenizers\\implementations\\sentencepiece_unigram.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\implementations\n",
            "      copying py_src\\tokenizers\\implementations\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\implementations\n",
            "      creating build\\lib.win-amd64-cpython-310\\tokenizers\\tools\n",
            "      copying py_src\\tokenizers\\tools\\visualizer.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\tools\n",
            "      copying py_src\\tokenizers\\tools\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\tools\n",
            "      copying py_src\\tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-310\\tokenizers\n",
            "      copying py_src\\tokenizers\\models\\__init__.pyi -> build\\lib.win-amd64-cpython-310\\tokenizers\\models\n",
            "      copying py_src\\tokenizers\\decoders\\__init__.pyi -> build\\lib.win-amd64-cpython-310\\tokenizers\\decoders\n",
            "      copying py_src\\tokenizers\\normalizers\\__init__.pyi -> build\\lib.win-amd64-cpython-310\\tokenizers\\normalizers\n",
            "      copying py_src\\tokenizers\\pre_tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-310\\tokenizers\\pre_tokenizers\n",
            "      copying py_src\\tokenizers\\processors\\__init__.pyi -> build\\lib.win-amd64-cpython-310\\tokenizers\\processors\n",
            "      copying py_src\\tokenizers\\trainers\\__init__.pyi -> build\\lib.win-amd64-cpython-310\\tokenizers\\trainers\n",
            "      copying py_src\\tokenizers\\tools\\visualizer-styles.css -> build\\lib.win-amd64-cpython-310\\tokenizers\\tools\n",
            "      running build_ext\n",
            "      running build_rust\n",
            "      error: can't find Rust compiler\n",
            "      \n",
            "      If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
            "      \n",
            "      To update pip, run:\n",
            "      \n",
            "          pip install --upgrade pip\n",
            "      \n",
            "      and then retry package installation.\n",
            "      \n",
            "      If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed building wheel for tokenizers\n",
            "ERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.15.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb) (3.1.30)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb) (2.28.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb) (5.9.1)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb) (1.24.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: pathtools in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb) (65.6.3)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: colorama in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Click!=8.0.0,>=7.0->wandb) (0.4.4)\n",
            "Requirement already satisfied: six>=1.4.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install tokenizers==0.10.0rc1\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "IGJsIqgRtEn-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import datasets\n",
        "import tokenizers\n",
        "import wandb\n",
        "from tqdm.auto import tqdm\n",
        "from nltk.util import ngrams\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FYu-_i_CeThC"
      },
      "source": [
        "## О формате заданий\n",
        "\n",
        "### Coding tasks\n",
        "\n",
        "\n",
        "Место для вашего кода отмечено блоками `# YOUR CODE STARTS` ... `#YOUR CODE ENDS` и ваше решение должно быть строго между ними. \n",
        "\n",
        "Чтобы решить задачу, вам придётся смотреть в документацию соответствующего фреймворка. Этот навык очень важен, и в начале мы будем намекать вам на название метода, который вам нужно использовать. Такой подход позволит плавно приблизить вас к более реалистичным задачам.\n",
        "\n",
        "\n",
        "\n",
        "![image.png](https://files.realpython.com/media/Practical-Text-Classification-with-Keras-and-Python_Watermark.fe326bd75146.jpg)\n",
        "\n",
        "Image source: [тык](https://realpython.com/python-keras-text-classification/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "LUvFcan-tG5e",
        "outputId": "3ab48820-0022-496a-ee5d-48f313eae75b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset imdb (C:/Users/Пользователь/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
            "100%|██████████| 3/3 [00:00<00:00, 16.83it/s]\n"
          ]
        }
      ],
      "source": [
        "text_dataset = datasets.load_dataset(\"imdb\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1JrixvHI6teb"
      },
      "source": [
        "**IMDB** - это датасет по классификации эмоциональной окраски. Вам нужно предсказать положительный ли отзыв к фильму по его тексту. Это довольно простая задача и она хорошо решается даже линейными моделями. Для доступа к нему мы используем библиотеку `datasets` - она содержит в себе много интересных текстовых датасетов.\n",
        "\n",
        "Тренировочная и тстовая части IMDB достаточно большие - каждая состоит из 25 тысяч примеров."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "GL4eJ8hcwHA_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oUVSXa2r7oak"
      },
      "source": [
        "Как мы видим, классы сбалансированны, что позволяет использовать accuracy как простую и интерпретируемую метрику, хорошо показывающую качество модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "wbCkXd6_7VU_"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_labels = [e['label'] for e in text_dataset['train']]\n",
        "plt.hist(train_labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "o04VWlLvwpDd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 25000\n",
              "})"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_dataset['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "SdqU7ZTiwrC9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.'"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_dataset['train']['text'][0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bVemry0mziTa"
      },
      "source": [
        "# Classification using a linear model\n",
        "\n",
        "Линейная модель - очень сильный бейзлайн и в некоторых задачах классификации вам даже не надо идти дальше линейной модели - она уже достаточно хороша. А также её можно написать менее чем в 10 строчекю Поэтому всегда стоит начинать решение любой задачи с ленейного бейзлайна.\n",
        "\n",
        "Давайте вспомним библиотеку `sklearn` и напишем линейную модельку. Для векторизации текста мы будем использовать `TfidfVectorizer`, а в качестве модели `LogisticRegression`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "fMU_c9pKxe0d"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "i5qXrSEXztwW"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "TfidfVectorizer()"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TASK 1.1: create TfidfVectorizer object and fit it on out training set texts\n",
        "# Our implementation is 2 lines\n",
        "# YOUR CODE STARTS\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(text_dataset['train']['text'])\n",
        "\n",
        "# YOUR CODE ENDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "RRkJP8yz2KPP"
      },
      "outputs": [],
      "source": [
        "# TASK 1.2:\n",
        "# 1. convert your texts to tf-idf vectors using .transform (training texts and test texts too)\n",
        "# 2. convert your labels into numpy arrays (both training and test labels)\n",
        "# Or implementatin is 4 lines\n",
        "\n",
        "# YOUR CODE STARTS\n",
        "X_train = vectorizer.transform(text_dataset['train']['text'])\n",
        "y_train = np.array(text_dataset['train']['label'])\n",
        "\n",
        "X_test = vectorizer.transform(text_dataset['test']['text'])\n",
        "y_test = np.array(text_dataset['test']['label'])\n",
        "# YOUR CODE ENDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "_FAAuos63UtS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<25000x74849 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 3445861 stored elements in Compressed Sparse Row format>,\n",
              " array([0, 0, 0, ..., 1, 1, 1]))"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "gnWo2pLB1ho0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(random_state=42)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TASK 1.3: create LogisticRegression model object and fit the model\n",
        "# Our implementation is 2 lines\n",
        "# YOUR CODE STARTS\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# YOUR CODE ENDS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RJRuIbVrqDpR"
      },
      "source": [
        "А теперь мы используем нашу модель для того, чтобы предсказать классы на тестовом сете и считаем accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "ZKCOA3SE3kSK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "print(type(predictions))\n",
        "print(type(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "pyO4CMzB3jds"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.88316"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# note that we can use vector operations, because we deal with numpy tensors\n",
        "accuracy = (predictions == y_test).mean()\n",
        "accuracy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AENaKt7huHd1"
      },
      "source": [
        "**OMG so accurate, much machine learning**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5NpZecL4qqI5"
      },
      "source": [
        "Давайте предскажем позитивны ли такие комментарии:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "XKlLVQUqsRlI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positive_comment = 'This movie is awesome!'\n",
        "\n",
        "vec = vectorizer.transform([positive_comment])\n",
        "model.predict(vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "CHtq-453t2Gb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "negative_comment = 'This movie is awful!'\n",
        "\n",
        "vec = vectorizer.transform([negative_comment])\n",
        "model.predict(vec)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm2GycUTTjgW"
      },
      "source": [
        "Как мы увидели, даже такая простая модель может хорошо классифицировать текст (accuracy 0.9 - это довольно много, тк выборка сбалансированна).\n",
        "\n",
        "Кстати, использование модели LinearSVM обычно работает даже лучше, чем логистическая регрессия. Рекомендуем попробовать и сравнить.\n",
        "\n",
        "Что такое SVM: [тык](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47)\n",
        "\n",
        "Ещё один простой метод улучшить линейную модель - использовать n-gram в вашем TF-IDF. Не забудьте указать параметр `max_features` (хорошое число 50 000), а то при большом количестве фичей модель может начать переобучаться."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8772"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CODE STARTS\n",
        "svm_model = LinearSVC(random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "accuracy = (svm_predictions == y_test).mean()\n",
        "accuracy\n",
        "# YOUR CODE ENDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.89436"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CODE STARTS\n",
        "vectorizer_n = TfidfVectorizer(ngram_range=(1, 2), max_features=50000)\n",
        "vectorizer_n.fit(text_dataset['train']['text'])\n",
        "\n",
        "X_train = vectorizer_n.transform(text_dataset['train']['text'])\n",
        "y_train = np.array(text_dataset['train']['label'])\n",
        "\n",
        "X_test = vectorizer_n.transform(text_dataset['test']['text'])\n",
        "y_test = np.array(text_dataset['test']['label'])\n",
        "\n",
        "\n",
        "model_n = LogisticRegression(random_state=42)\n",
        "model_n.fit(X_train, y_train)\n",
        "\n",
        "n_predictions = model_n.predict(X_test)\n",
        "accuracy = (n_predictions == y_test).mean()\n",
        "accuracy\n",
        "\n",
        "# YOUR CODE ENDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "vectorizers",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
