{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from hdfs.client import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# читаем с HDFS\n",
    "def read_hdfs_file(client, filename):\n",
    "    lines = []\n",
    "    with client.read(filename, encoding='utf-8', delimiter='\\n') as reader:\n",
    "        for line in reader:\n",
    "            lines.append(line.strip())\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# записываем данные в файл hdfs\n",
    "def write_to_hdfs(client, hdfs_path, data):\n",
    "    client.write(hdfs_path, data, overwrite=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем файлы из hdfs на локальный\n",
    "def get_from_hdfs(client, hdfs_path, local_path):\n",
    "    client.download(hdfs_path, local_path, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем файл в hdfs\n",
    "def put_to_hdfs(client, local_path, hdfs_path):\n",
    "    client.upload(hdfs_path, local_path, cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем HDFS клиент и создаем подключение к адресу HDFS\n",
    "client = Client(\"http://adh-master:9870\", root=\"/\", timeout=5, session=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "HdfsError",
     "evalue": "File /tmp/ai/names/test.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHdfsError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\SkillFactory\\SF_DataScience\\Current_tasks\\DE-6.ipynb Ячейка 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/SkillFactory/SF_DataScience/Current_tasks/DE-6.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m read_hdfs_file(client, \u001b[39m'\u001b[39;49m\u001b[39m/tmp/ai/names/test.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32mc:\\SkillFactory\\SF_DataScience\\Current_tasks\\DE-6.ipynb Ячейка 7\u001b[0m in \u001b[0;36mread_hdfs_file\u001b[1;34m(client, filename)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/SkillFactory/SF_DataScience/Current_tasks/DE-6.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_hdfs_file\u001b[39m(client, filename):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/SkillFactory/SF_DataScience/Current_tasks/DE-6.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     lines \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/SkillFactory/SF_DataScience/Current_tasks/DE-6.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mwith\u001b[39;00m client\u001b[39m.\u001b[39mread(filename, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m, delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m reader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/SkillFactory/SF_DataScience/Current_tasks/DE-6.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m reader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/SkillFactory/SF_DataScience/Current_tasks/DE-6.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m             lines\u001b[39m.\u001b[39mappend(line\u001b[39m.\u001b[39mstrip())\n",
      "File \u001b[1;32mc:\\Users\\Пользователь\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[0;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Пользователь\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\hdfs\\client.py:732\u001b[0m, in \u001b[0;36mClient.read\u001b[1;34m(self, hdfs_path, offset, length, buffer_size, encoding, chunk_size, delimiter, progress)\u001b[0m\n\u001b[0;32m    730\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDelimiter splitting incompatible with chunk size.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    731\u001b[0m _logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mReading file \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, hdfs_path)\n\u001b[1;32m--> 732\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(\n\u001b[0;32m    733\u001b[0m   hdfs_path,\n\u001b[0;32m    734\u001b[0m   offset\u001b[39m=\u001b[39;49moffset,\n\u001b[0;32m    735\u001b[0m   length\u001b[39m=\u001b[39;49mlength,\n\u001b[0;32m    736\u001b[0m   buffersize\u001b[39m=\u001b[39;49mbuffer_size,\n\u001b[0;32m    737\u001b[0m )\n\u001b[0;32m    738\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    739\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunk_size \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m delimiter:\n",
      "File \u001b[1;32mc:\\Users\\Пользователь\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\hdfs\\client.py:118\u001b[0m, in \u001b[0;36m_Request.to_method.<locals>.api_handler\u001b[1;34m(client, hdfs_path, data, strict, **params)\u001b[0m\n\u001b[0;32m    116\u001b[0m   \u001b[39mif\u001b[39;00m err\u001b[39m.\u001b[39mexception \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mRetriableException\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mStandbyException\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m strict:\n\u001b[1;32m--> 118\u001b[0m       \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m    121\u001b[0m attempted_hosts\u001b[39m.\u001b[39madd(host)\n",
      "\u001b[1;31mHdfsError\u001b[0m: File /tmp/ai/names/test.csv not found."
     ]
    }
   ],
   "source": [
    "data = read_hdfs_file(client, '/tmp/ai/names/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c97e36f5c1aa02871b4149eafcab2ec871d39d20911a3254ab29c2172503796d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
